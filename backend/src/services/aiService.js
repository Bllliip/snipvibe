const OpenAI = require('openai');
const ffmpeg = require('fluent-ffmpeg');
const path = require('path');
const fs = require('fs').promises;
const logger = require('../utils/logger');

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY
});

// Generate metadata for video
async function generateMetadata(videoPath, platform) {
  try {
    // Extract a frame for analysis
    const framePath = await extractFrame(videoPath);
    
    // Analyze video content
    const analysis = await analyzeVideoContent(framePath);
    
    // Generate platform-specific metadata
    const metadata = await generatePlatformMetadata(analysis, platform);
    
    // Clean up temp frame
    await fs.unlink(framePath);
    
    return metadata;
  } catch (error) {
    logger.error('AI metadata generation failed:', error);
    return {
      title: 'Generated Video Clip',
      description: 'Short video clip generated by SnipVibe',
      hashtags: ['#video', '#clip', '#snipvibe']
    };
  }
}

// Find best clip segment using AI
async function findBestClip(videoPath, maxDuration) {
  try {
    // Get video metadata
    const metadata = await getVideoMetadata(videoPath);
    const videoDuration = metadata.format.duration;
    
    if (videoDuration <= maxDuration) {
      return { start: 0, end: videoDuration };
    }
    
    // Extract multiple frames for analysis
    const frames = await extractMultipleFrames(videoPath, 5);
    
    // Analyze frames to find most engaging segment
    const bestSegment = await findEngagingSegment(frames, videoDuration, maxDuration);
    
    // Clean up temp frames
    for (const frame of frames) {
      await fs.unlink(frame.path);
    }
    
    return bestSegment;
  } catch (error) {
    logger.error('AI clip detection failed:', error);
    // Fallback to middle segment
    const metadata = await getVideoMetadata(videoPath);
    const videoDuration = metadata.format.duration;
    const start = Math.max(0, (videoDuration - maxDuration) / 2);
    return { start, end: start + maxDuration };
  }
}

// Extract single frame from video
async function extractFrame(videoPath) {
  const framePath = path.join(process.env.UPLOAD_DIR || './uploads', `frame_${Date.now()}.jpg`);
  
  return new Promise((resolve, reject) => {
    ffmpeg(videoPath)
      .screenshots({
        count: 1,
        folder: path.dirname(framePath),
        filename: path.basename(framePath),
        timemarks: ['50%']
      })
      .on('end', () => resolve(framePath))
      .on('error', reject);
  });
}

// Extract multiple frames from video
async function extractMultipleFrames(videoPath, count) {
  const frames = [];
  const tempDir = process.env.UPLOAD_DIR || './uploads';
  
  return new Promise((resolve, reject) => {
    const timemarks = [];
    for (let i = 1; i <= count; i++) {
      timemarks.push(`${(i * 100 / (count + 1))}%`);
    }
    
    ffmpeg(videoPath)
      .screenshots({
        count,
        folder: tempDir,
        filename: `frame_${Date.now()}_%i.jpg`,
        timemarks
      })
      .on('end', () => {
        // Build frame objects with timestamps
        for (let i = 1; i <= count; i++) {
          frames.push({
            path: path.join(tempDir, `frame_${Date.now()}_${i}.jpg`),
            timestamp: (i * 100 / (count + 1)) / 100
          });
        }
        resolve(frames);
      })
      .on('error', reject);
  });
}

// Analyze video content using OpenAI Vision
async function analyzeVideoContent(imagePath) {
  try {
    const imageBuffer = await fs.readFile(imagePath);
    const base64Image = imageBuffer.toString('base64');
    
    const response = await openai.chat.completions.create({
      model: "gpt-4-vision-preview",
      messages: [
        {
          role: "user",
          content: [
            {
              type: "text",
              text: "Analyze this video frame and describe the content, mood, and key visual elements. Focus on what would make this engaging for social media."
            },
            {
              type: "image_url",
              image_url: {
                url: `data:image/jpeg;base64,${base64Image}`
              }
            }
          ]
        }
      ],
      max_tokens: 300
    });
    
    return response.choices[0].message.content;
  } catch (error) {
    logger.error('OpenAI vision analysis failed:', error);
    return 'Video content analysis unavailable';
  }
}

// Generate platform-specific metadata
async function generatePlatformMetadata(analysis, platform) {
  try {
    const platformPrompts = {
      tiktok: "Generate a catchy TikTok title and description with trending hashtags",
      youtube: "Generate a YouTube Shorts title and description with SEO-friendly hashtags",
      reels: "Generate an Instagram Reels title and description with popular hashtags",
      custom: "Generate a general social media title and description with relevant hashtags"
    };
    
    const prompt = `Based on this video analysis: "${analysis}"
    
    ${platformPrompts[platform] || platformPrompts.custom}
    
    Return a JSON object with:
    - title: engaging title (max 100 characters)
    - description: compelling description (max 300 characters)
    - hashtags: array of 5-10 relevant hashtags
    
    Make it engaging and platform-appropriate.`;
    
    const response = await openai.chat.completions.create({
      model: "gpt-3.5-turbo",
      messages: [{ role: "user", content: prompt }],
      max_tokens: 400
    });
    
    const content = response.choices[0].message.content;
    const jsonMatch = content.match(/\{[\s\S]*\}/);
    
    if (jsonMatch) {
      return JSON.parse(jsonMatch[0]);
    }
    
    throw new Error('Invalid JSON response from OpenAI');
  } catch (error) {
    logger.error('Metadata generation failed:', error);
    return generateFallbackMetadata(platform);
  }
}

// Find most engaging segment
async function findEngagingSegment(frames, videoDuration, maxDuration) {
  try {
    // Analyze each frame for engagement factors
    const frameAnalyses = await Promise.all(
      frames.map(async (frame) => {
        const analysis = await analyzeVideoContent(frame.path);
        return {
          timestamp: frame.timestamp * videoDuration,
          engagement: calculateEngagementScore(analysis)
        };
      })
    );
    
    // Find frame with highest engagement score
    const bestFrame = frameAnalyses.reduce((best, current) => 
      current.engagement > best.engagement ? current : best
    );
    
    // Center the clip around the best frame
    const clipCenter = bestFrame.timestamp;
    const start = Math.max(0, clipCenter - maxDuration / 2);
    const end = Math.min(videoDuration, start + maxDuration);
    
    return { start, end };
  } catch (error) {
    logger.error('Engagement analysis failed:', error);
    // Fallback to middle segment
    const start = Math.max(0, (videoDuration - maxDuration) / 2);
    return { start, end: start + maxDuration };
  }
}

// Calculate engagement score based on content analysis
function calculateEngagementScore(analysis) {
  const engagementKeywords = [
    'action', 'movement', 'dynamic', 'colorful', 'bright',
    'people', 'faces', 'expressions', 'interaction', 'activity',
    'interesting', 'engaging', 'vibrant', 'lively', 'animated'
  ];
  
  let score = 0;
  const lowerAnalysis = analysis.toLowerCase();
  
  engagementKeywords.forEach(keyword => {
    if (lowerAnalysis.includes(keyword)) {
      score += 1;
    }
  });
  
  return score;
}

// Generate fallback metadata
function generateFallbackMetadata(platform) {
  const fallbacks = {
    tiktok: {
      title: "Amazing Video Clip! ðŸ”¥",
      description: "Check out this incredible moment! #viral #amazing #fyp",
      hashtags: ["#viral", "#fyp", "#amazing", "#video", "#tiktok"]
    },
    youtube: {
      title: "Incredible Video Moment - YouTube Shorts",
      description: "Don't miss this amazing clip! Subscribe for more content.",
      hashtags: ["#shorts", "#viral", "#amazing", "#youtube", "#video"]
    },
    reels: {
      title: "Must-See Video Clip âœ¨",
      description: "This moment is everything! Follow for more amazing content.",
      hashtags: ["#reels", "#viral", "#amazing", "#instagram", "#video"]
    },
    custom: {
      title: "Amazing Video Clip",
      description: "Check out this incredible moment from our video!",
      hashtags: ["#video", "#clip", "#amazing", "#viral", "#content"]
    }
  };
  
  return fallbacks[platform] || fallbacks.custom;
}

// Get video metadata helper
function getVideoMetadata(videoPath) {
  return new Promise((resolve, reject) => {
    ffmpeg.ffprobe(videoPath, (err, metadata) => {
      if (err) reject(err);
      else resolve(metadata);
    });
  });
}

module.exports = {
  generateMetadata,
  findBestClip
};